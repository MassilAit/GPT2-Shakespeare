{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPT2 project"
      ],
      "metadata": {
        "id": "JkUKLtf0OQJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and setups"
      ],
      "metadata": {
        "id": "KRinQZXfOmCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n",
        "!pip install tiktoken\n",
        "!pip install wandb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NDfRP4eYOpCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataloader import make_loaders\n",
        "from model import GPT, GPTConfig\n",
        "from train import train\n",
        "from text_generation import generate_text\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "aRmzeZxtO5CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using\", device)"
      ],
      "metadata": {
        "id": "DSMqcOwTPNJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "QD9mMkBJR15h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and fine tuning"
      ],
      "metadata": {
        "id": "4Vmix_UQURd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "fOmGMv8fO-7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPT(GPTConfig()) # or : model=GPT.from_pretrained(\"gpt2\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "compiled_model = torch.compile(model)"
      ],
      "metadata": {
        "id": "71hSexBEPE1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "cYLtu25OPToq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader = make_loaders(\n",
        "        path=\"input.txt\",\n",
        "        block_size=1024,\n",
        "        overlap=896 ,\n",
        "        batch_size=16,\n",
        "        val_frac=0.1,\n",
        "    )"
      ],
      "metadata": {
        "id": "lh_9YrLdPSp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "FMl6KjvfPbfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train(\n",
        "    compiled_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs        = 5,\n",
        "    lr            = 1e-5,     # base LR (warm-up will ramp to this)\n",
        "    device        = device,\n",
        "    clip_grad_norm= 1.0,      # keep gradients stable\n",
        "    weight_decay  = 0.1,     # regularise big GPT on small corpus\n",
        "    warmup_steps  = 200,      # ~2â€“3 batches on batch=4, seq=1024\n",
        "    wandb_project=\"tiny-shakespeare-gpt\",\n",
        "    wandb_run_name=\"pre-trained\",\n",
        "    max_val_loss_increase = 1.03, #early-stoping\n",
        "    early_stopping_patience = 2   #early-stoping\n",
        ")\n"
      ],
      "metadata": {
        "id": "WI_MlViUPehY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"gpt2_shakespear.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), name)"
      ],
      "metadata": {
        "id": "1ur2NtJ0t7v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text generation and analysis"
      ],
      "metadata": {
        "id": "S8m2ybMLPRaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load models"
      ],
      "metadata": {
        "id": "-FjTobJ2U3FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(GPTConfig())\n",
        "\n",
        "name = \"gpt2_shakespeare.pt\"\n",
        "model.load_state_dict(torch.load(name))\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "LY9bfm_EU5X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"ALBERT EINSTEIN\"\n",
        "\n",
        "generated_text=generate_text(model, prompt, device, top_p=0.9, temperature=0.8)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "KoZ48TdSPdQ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}